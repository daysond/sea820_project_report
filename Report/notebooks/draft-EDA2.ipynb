{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fffb7d8e",
   "metadata": {},
   "source": [
    "# EDA 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b7dda3",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "81df0f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 487235 entries, 0 to 487234\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   text       487235 non-null  object \n",
      " 1   generated  487235 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 7.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated\n",
       "0  Cars. Cars have been around since they became ...        0.0\n",
       "1  Transportation is a large necessity in most co...        0.0\n",
       "2  \"America's love affair with it's vehicles seem...        0.0\n",
       "3  How often do you ride in a car? Do you drive a...        0.0\n",
       "4  Cars are a wonderful thing. They are perhaps o...        0.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from your local path\n",
    "df = pd.read_csv('./AI_Human.csv')  \n",
    "\n",
    "# Display basic information about the dataset\n",
    "df.info()\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "64eb81fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cars. Cars have been around since they became famous in the 1900s, when Henry Ford created and built the first ModelT. Cars have played a major role in our every day lives since then. But now, people are starting to question if limiting car usage would be a good thing. To me, limiting the use of cars might be a good thing to do.\\n\\nIn like matter of this, article, \"In German Suburb, Life Goes On Without Cars,\" by Elizabeth Rosenthal states, how automobiles are the linchpin of suburbs, where middle class families from either Shanghai or Chicago tend to make their homes. Experts say how this is a huge impediment to current efforts to reduce greenhouse gas emissions from tailpipe. Passenger cars are responsible for 12 percent of greenhouse gas emissions in Europe...and up to 50 percent in some carintensive areas in the United States. Cars are the main reason for the greenhouse gas emissions because of a lot of people driving them around all the time getting where they need to go. Article, \"Paris bans driving due to smog,\" by Robert Duffer says, how Paris, after days of nearrecord pollution, enforced a partial driving ban to clear the air of the global city. It also says, how on Monday, motorist with evennumbered license plates were ordered to leave their cars at home or be fined a 22euro fine 31. The same order would be applied to oddnumbered plates the following day. Cars are the reason for polluting entire cities like Paris. This shows how bad cars can be because, of all the pollution that they can cause to an entire city.\\n\\nLikewise, in the article, \"Carfree day is spinning into a big hit in Bogota,\" by Andrew Selsky says, how programs that\\'s set to spread to other countries, millions of Columbians hiked, biked, skated, or took the bus to work during a carfree day, leaving streets of this capital city eerily devoid of traffic jams. It was the third straight year cars have been banned with only buses and taxis permitted for the Day Without Cars in the capital city of 7 million. People like the idea of having carfree days because, it allows them to lesson the pollution that cars put out of their exhaust from people driving all the time. The article also tells how parks and sports centers have bustled throughout the city uneven, pitted sidewalks have been replaced by broad, smooth sidewalks rushhour restrictions have dramatically cut traffic and new restaurants and upscale shopping districts have cropped up. Having no cars has been good for the country of Columbia because, it has aloud them to repair things that have needed repairs for a long time, traffic jams have gone down, and restaurants and shopping districts have popped up, all due to the fact of having less cars around.\\n\\nIn conclusion, the use of less cars and having carfree days, have had a big impact on the environment of cities because, it is cutting down the air pollution that the cars have majorly polluted, it has aloud countries like Columbia to repair sidewalks, and cut down traffic jams. Limiting the use of cars would be a good thing for America. So we should limit the use of cars by maybe riding a bike, or maybe walking somewhere that isn\\'t that far from you and doesn\\'t need the use of a car to get you there. To me, limiting the use of cars might be a good thing to do.'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6d7d62",
   "metadata": {},
   "source": [
    "## Check Null Values & Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "feec84a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "generated    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the dataset\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa4621",
   "metadata": {},
   "source": [
    "## Data Cleaning and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "946dd6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, generated]\n",
       "Index: []"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_mask = df.duplicated(subset='text', keep=False)\n",
    "df[duplicate_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "09364980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(text):\n",
    "    tags = ['\\n', '\\'']\n",
    "    for tag in tags:\n",
    "        text = text.replace(tag, ' ' if tag == '\\n' else '')\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "df['text'] = df['text'].apply(remove_tags)\n",
    "\n",
    "# https://www.kaggle.com/code/saurabhkailaskuche/ai-generated-vs-human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f40e7dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with text length 0: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>Code] [Email Address] [Phone Number]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>]  [Email]  [Phone Number]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>] [Email] [Phone Number]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>] [Email Address] [Phone Number]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28737</th>\n",
       "      <td>Facial action coding</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29318</th>\n",
       "      <td>Community service is an integral part of ever...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29331</th>\n",
       "      <td>Community service.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29337</th>\n",
       "      <td>Community service refers to the activities an...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29374</th>\n",
       "      <td>Write an essay on the topic \"A Cowboy Who Rod...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29394</th>\n",
       "      <td>Please provide the essay on this topic.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29500</th>\n",
       "      <td>Introduction:  Distance learning</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29547</th>\n",
       "      <td>Elect</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29763</th>\n",
       "      <td>Summer projects are an excellent opportunity ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30436</th>\n",
       "      <td>The electoral college was established in  Ans...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30859</th>\n",
       "      <td>Write an essay of between 300 and</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77489</th>\n",
       "      <td>the memorable teacher ever had\\r \\r was a teac...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77765</th>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78008</th>\n",
       "      <td>Title: Embracing an Alternative Future - Ex...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78110</th>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78136</th>\n",
       "      <td>Consider the social, economic, and environmen...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78298</th>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78700</th>\n",
       "      <td>Important Elements and Their Significance in ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79352</th>\n",
       "      <td>Discuss the benefits and challenges of driver...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79450</th>\n",
       "      <td>Exploring the future of transportation and ou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80930</th>\n",
       "      <td>Write an essay discussing the challenges, ac...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80931</th>\n",
       "      <td>Subject: Exploring Venus: The Future of Human...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81000</th>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169322</th>\n",
       "      <td>In recent years, there has been a growing trend</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191876</th>\n",
       "      <td>MMM... H-hi Mr./Ms. S-s-s-s-s-s-s-s-s-s-s-s-s-...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229136</th>\n",
       "      <td>MMM... Hi Mr./Ms. Ssssssssssssssssssssssssssss...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259325</th>\n",
       "      <td>] [Email Address] [Those Number]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  generated  \\\n",
       "2380                 Code] [Email Address] [Phone Number]        1.0   \n",
       "2381                           ]  [Email]  [Phone Number]        1.0   \n",
       "2384                                                    ]        1.0   \n",
       "2385                             ] [Email] [Phone Number]        1.0   \n",
       "2388                     ] [Email Address] [Phone Number]        1.0   \n",
       "28737                                Facial action coding        1.0   \n",
       "29318    Community service is an integral part of ever...        1.0   \n",
       "29331                                  Community service.        1.0   \n",
       "29337    Community service refers to the activities an...        1.0   \n",
       "29374    Write an essay on the topic \"A Cowboy Who Rod...        1.0   \n",
       "29394             Please provide the essay on this topic.        1.0   \n",
       "29500                    Introduction:  Distance learning        1.0   \n",
       "29547                                               Elect        1.0   \n",
       "29763    Summer projects are an excellent opportunity ...        1.0   \n",
       "30436    The electoral college was established in  Ans...        1.0   \n",
       "30859                   Write an essay of between 300 and        1.0   \n",
       "77489   the memorable teacher ever had\\r \\r was a teac...        0.0   \n",
       "77765                                                            1.0   \n",
       "78008      Title: Embracing an Alternative Future - Ex...        1.0   \n",
       "78110                                                            1.0   \n",
       "78136    Consider the social, economic, and environmen...        1.0   \n",
       "78298                                                            1.0   \n",
       "78700    Important Elements and Their Significance in ...        1.0   \n",
       "79352    Discuss the benefits and challenges of driver...        1.0   \n",
       "79450    Exploring the future of transportation and ou...        1.0   \n",
       "80930     Write an essay discussing the challenges, ac...        1.0   \n",
       "80931    Subject: Exploring Venus: The Future of Human...        1.0   \n",
       "81000                                                            1.0   \n",
       "169322    In recent years, there has been a growing trend        1.0   \n",
       "191876  MMM... H-hi Mr./Ms. S-s-s-s-s-s-s-s-s-s-s-s-s-...        1.0   \n",
       "229136  MMM... Hi Mr./Ms. Ssssssssssssssssssssssssssss...        1.0   \n",
       "259325                   ] [Email Address] [Those Number]        1.0   \n",
       "\n",
       "        text_length  \n",
       "2380              5  \n",
       "2381              4  \n",
       "2384              1  \n",
       "2385              4  \n",
       "2388              5  \n",
       "28737             3  \n",
       "29318            14  \n",
       "29331             2  \n",
       "29337            11  \n",
       "29374            12  \n",
       "29394             7  \n",
       "29500             3  \n",
       "29547             1  \n",
       "29763            11  \n",
       "30436             8  \n",
       "30859             7  \n",
       "77489            14  \n",
       "77765             0  \n",
       "78008            11  \n",
       "78110             0  \n",
       "78136            11  \n",
       "78298             0  \n",
       "78700             8  \n",
       "79352            14  \n",
       "79450            10  \n",
       "80930            13  \n",
       "80931             9  \n",
       "81000             0  \n",
       "169322            9  \n",
       "191876            4  \n",
       "229136            4  \n",
       "259325            5  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure text_length is calculated\n",
    "df['text_length'] = df['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Find rows with text length 0\n",
    "empty_rows = df[df['text_length'] <= 15]\n",
    "\n",
    "# Display the number of such rows and optionally print them\n",
    "print(f\"Number of rows with text length 0: {len(empty_rows)}\")\n",
    "empty_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "96cee9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text_length'] >= 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "804f2535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import preprocess_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dd22f3",
   "metadata": {},
   "source": [
    "## Process the Data in Parallel using Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "737a5d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "num_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "aa7bd222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = Parallel(n_jobs=num_cores)(\n",
    "    delayed(preprocess_text)(text) for text in df['text']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "af4212a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>text_length</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>584</td>\n",
       "      <td>car car around since became famous 1900s henry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>462</td>\n",
       "      <td>transportation large necessity country worldwi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Americas love affair with its vehicles seems ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>744</td>\n",
       "      <td>america love affair vehicle seems cooling say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>686</td>\n",
       "      <td>often ride car drive one motor vehicle work st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>871</td>\n",
       "      <td>car wonderful thing perhaps one world greatest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated  text_length  \\\n",
       "0  Cars. Cars have been around since they became ...        0.0          584   \n",
       "1  Transportation is a large necessity in most co...        0.0          462   \n",
       "2  \"Americas love affair with its vehicles seems ...        0.0          744   \n",
       "3  How often do you ride in a car? Do you drive a...        0.0          686   \n",
       "4  Cars are a wonderful thing. They are perhaps o...        0.0          871   \n",
       "\n",
       "                                              tokens  \n",
       "0  car car around since became famous 1900s henry...  \n",
       "1  transportation large necessity country worldwi...  \n",
       "2  america love affair vehicle seems cooling say ...  \n",
       "3  often ride car drive one motor vehicle work st...  \n",
       "4  car wonderful thing perhaps one world greatest...  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "18bdc611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 250972\n"
     ]
    }
   ],
   "source": [
    "# Split all tokens and flatten them into a single list\n",
    "all_tokens = df['tokens'].str.split().explode()\n",
    "\n",
    "# Get number of unique tokens\n",
    "unique_token_count = all_tokens.nunique()\n",
    "print(\"Number of unique tokens:\", unique_token_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9368419a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487203, 4)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20426450",
   "metadata": {},
   "source": [
    "## Find & Filter Similar Rows (added later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0adbd3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found candidate near-duplicates: 1568155\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx_a</th>\n",
       "      <th>idx_b</th>\n",
       "      <th>overlap_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1385</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.906404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1385</td>\n",
       "      <td>1391</td>\n",
       "      <td>0.866995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1389</td>\n",
       "      <td>1391</td>\n",
       "      <td>0.914692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1395</td>\n",
       "      <td>1397</td>\n",
       "      <td>0.930693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1395</td>\n",
       "      <td>1398</td>\n",
       "      <td>0.955224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx_a  idx_b  overlap_coeff\n",
       "0   1385   1389       0.906404\n",
       "1   1385   1391       0.866995\n",
       "2   1389   1391       0.914692\n",
       "3   1395   1397       0.930693\n",
       "4   1395   1398       0.955224"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------- Config ----------\n",
    "THRESH_OVERLAP = 0.85        # your “90% overlapping tokens” requirement\n",
    "NUM_PERM = 64                # MinHash permutations (64 is a good accuracy/memory tradeoff)\n",
    "LSH_JACCARD_THRESHOLD = 0.80 # LSH threshold (slightly lower to avoid missing borderline pairs)\n",
    "\n",
    "# ---------- Imports ----------\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "from joblib import Parallel, delayed\n",
    "import math\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def tokens_to_set(tokens_str: str):\n",
    "    # tokens column is space-separated; convert to a set of unique tokens\n",
    "    # (if your 'tokens' already has unique words, this is cheap)\n",
    "    return set(tokens_str.split())\n",
    "\n",
    "def minhash_from_set(s: set, num_perm=NUM_PERM) -> MinHash:\n",
    "    m = MinHash(num_perm=num_perm)\n",
    "    for w in s:\n",
    "        m.update(w.encode('utf-8'))\n",
    "    return m\n",
    "\n",
    "def overlap_coeff(a: set, b: set) -> float:\n",
    "    # |A ∩ B| / min(|A|, |B|)\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    return len(a & b) / float(min(len(a), len(b)))\n",
    "\n",
    "# ---------- Main (Incremental LSH to limit memory) ----------\n",
    "# We iterate rows once; for each row:\n",
    "# 1) build its MinHash\n",
    "# 2) query LSH for candidates among prior rows\n",
    "# 3) verify with exact overlap\n",
    "# 4) insert into LSH\n",
    "# This avoids querying every pair twice and keeps RAM in check.\n",
    "\n",
    "tokens_series = df['tokens']      # <- your DataFrame column\n",
    "lsh = MinHashLSH(threshold=LSH_JACCARD_THRESHOLD, num_perm=NUM_PERM)\n",
    "\n",
    "similar_pairs = []  # will store tuples: (i, j, overlap)\n",
    "# If you expect many matches, consider writing to disk in chunks instead of keeping all in RAM.\n",
    "\n",
    "for i, tok_str in enumerate(tokens_series):\n",
    "    A = tokens_to_set(tok_str)\n",
    "\n",
    "    # Build MinHash for this row\n",
    "    mh = minhash_from_set(A)\n",
    "\n",
    "    # Get candidates among previously inserted rows\n",
    "    candidates = lsh.query(mh)\n",
    "\n",
    "    # Verify with exact overlap, report each pair once (j < i because only previous inserted)\n",
    "    for j in candidates:\n",
    "        B = tokens_to_set(tokens_series.iloc[j])\n",
    "        oc = overlap_coeff(A, B)\n",
    "        if oc >= THRESH_OVERLAP:\n",
    "            similar_pairs.append((j, i, oc))  # store (older_index, current_index, score)\n",
    "\n",
    "    # Insert current row into index *after* querying to avoid self/duplicate matches\n",
    "    lsh.insert(i, mh)\n",
    "\n",
    "# Convert to a DataFrame if you want\n",
    "import pandas as pd\n",
    "pairs_df = pd.DataFrame(similar_pairs, columns=['idx_a', 'idx_b', 'overlap_coeff'])\n",
    "print(\"Found candidate near-duplicates:\", len(pairs_df))\n",
    "pairs_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8ccd4a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total similar groups (connected components, size ≥ 2): 52354\n",
      "Pure groups: 52317   Mixed groups: 37\n",
      "\n",
      "Group size distribution (size -> #groups):\n",
      "size\n",
      "2     3013\n",
      "3     1764\n",
      "4     3660\n",
      "5     6356\n",
      "6     8320\n",
      "7     8512\n",
      "8     6340\n",
      "9     4027\n",
      "10    2049\n",
      "11    1155\n",
      "12     982\n",
      "13    1029\n",
      "14    1006\n",
      "15     925\n",
      "16     755\n",
      "17     536\n",
      "18     397\n",
      "19     292\n",
      "20     187\n",
      "21     169\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 10 largest groups with label composition:\n",
      "label  group_id  n_human  n_ai  size\n",
      "0          2149       74     0    74\n",
      "1           512       32     0    32\n",
      "2           239       31     0    31\n",
      "3           114       31     0    31\n",
      "4          1144       31     0    31\n",
      "5           295       31     0    31\n",
      "6           203       31     0    31\n",
      "7           385       31     0    31\n",
      "8           708       30     0    30\n",
      "9          1028       30     0    30\n",
      "\n",
      "Largest group id: 2149  size: 74\n",
      "human    74\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Inputs assumed ---\n",
    "# df: your original DataFrame with column 'generated' (0/1)\n",
    "# pairs_df: DataFrame with columns ['idx_a','idx_b','overlap_coeff'] from your near-duplicate finder\n",
    "\n",
    "# Safety checks\n",
    "assert 'generated' in df.columns\n",
    "assert {'idx_a','idx_b'}.issubset(pairs_df.columns)\n",
    "\n",
    "# Use positional labels array to avoid index/key issues\n",
    "labels_arr = df['generated'].astype(int).to_numpy()\n",
    "N = len(df)\n",
    "\n",
    "# Edges as numpy arrays (ints)\n",
    "a = pairs_df['idx_a'].to_numpy(dtype=np.int64)\n",
    "b = pairs_df['idx_b'].to_numpy(dtype=np.int64)\n",
    "\n",
    "# --- Union-Find (Disjoint Set) over N rows (fast & memory-light) ---\n",
    "class DSU:\n",
    "    def __init__(self, n):\n",
    "        self.parent = np.arange(n, dtype=np.int64)\n",
    "        self.size = np.ones(n, dtype=np.int64)\n",
    "    def find(self, x):\n",
    "        # path compression\n",
    "        while self.parent[x] != x:\n",
    "            self.parent[x] = self.parent[self.parent[x]]\n",
    "            x = self.parent[x]\n",
    "        return x\n",
    "    def union(self, x, y):\n",
    "        rx, ry = self.find(x), self.find(y)\n",
    "        if rx == ry: \n",
    "            return\n",
    "        # union by size\n",
    "        if self.size[rx] < self.size[ry]:\n",
    "            rx, ry = ry, rx\n",
    "        self.parent[ry] = rx\n",
    "        self.size[rx] += self.size[ry]\n",
    "\n",
    "dsu = DSU(N)\n",
    "for i, j in zip(a, b):\n",
    "    dsu.union(i, j)\n",
    "\n",
    "# Only nodes that appear in at least one pair\n",
    "involved = np.unique(np.concatenate([a, b]))\n",
    "\n",
    "# Root for each involved node -> group id 0..G-1\n",
    "roots = np.array([dsu.find(i) for i in involved], dtype=np.int64)\n",
    "uniq_roots, group_ids = np.unique(roots, return_inverse=True)\n",
    "\n",
    "# Build nodes_df: each member with its group and label\n",
    "nodes_df = pd.DataFrame({\n",
    "    'row_idx': involved,           # positional row index in df\n",
    "    'group_id': group_ids,         # 0..num_groups-1\n",
    "    'label':   labels_arr[involved]\n",
    "})\n",
    "\n",
    "# Per-group label composition\n",
    "label_counts = (nodes_df\n",
    "                .groupby(['group_id','label'])\n",
    "                .size()\n",
    "                .unstack(fill_value=0)\n",
    "                .rename(columns={0:'n_human', 1:'n_ai'}))\n",
    "\n",
    "label_counts['size'] = label_counts['n_human'] + label_counts['n_ai']\n",
    "label_counts = label_counts.sort_values('size', ascending=False)\n",
    "\n",
    "# Keep only true \"similarity groups\" (size >= 2)\n",
    "label_counts = label_counts[label_counts['size'] >= 2]\n",
    "num_groups = label_counts.shape[0]\n",
    "\n",
    "print(f\"Total similar groups (connected components, size ≥ 2): {num_groups}\")\n",
    "\n",
    "# Pure vs mixed groups\n",
    "pure_groups = (label_counts[['n_human','n_ai']].min(axis=1) == 0).sum()\n",
    "mixed_groups = num_groups - pure_groups\n",
    "print(f\"Pure groups: {pure_groups}   Mixed groups: {mixed_groups}\")\n",
    "\n",
    "# Size distribution (first few sizes)\n",
    "print(\"\\nGroup size distribution (size -> #groups):\")\n",
    "print(label_counts['size'].value_counts().sort_index().head(20))\n",
    "\n",
    "# Top 10 largest groups with composition\n",
    "summary = label_counts.reset_index()\n",
    "print(\"\\nTop 10 largest groups with label composition:\")\n",
    "print(summary.head(10))\n",
    "\n",
    "# Members of the largest group (positional row indices in df)\n",
    "largest_gid = summary.iloc[0]['group_id'] if len(summary) else None\n",
    "if largest_gid is not None:\n",
    "    members_largest = nodes_df.loc[nodes_df['group_id'] == largest_gid, 'row_idx'].tolist()\n",
    "    print(f\"\\nLargest group id: {largest_gid}  size: {len(members_largest)}\")\n",
    "    # Example: inspect their labels quickly\n",
    "    print(pd.Series(labels_arr[members_largest]).value_counts().rename(index={0:'human',1:'ai'}))\n",
    "    # You can also peek at the texts:\n",
    "    # df.iloc[members_largest][['generated','text']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3a61bf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar rows total: 403589\n",
      "Label 0 (human)   : 262659\n",
      "Label 1 (AI)      : 140930\n",
      "Label 0 %         : 65.081%\n",
      "Label 1 %         : 34.919%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# safety checks\n",
    "assert {'idx_a','idx_b'}.issubset(pairs_df.columns)\n",
    "assert 'generated' in df.columns\n",
    "\n",
    "# labels as a positional array\n",
    "labels_arr = df['generated'].astype(int).to_numpy()\n",
    "\n",
    "# all unique rows that appear in at least one similar-pair edge\n",
    "involved = np.unique(pairs_df[['idx_a','idx_b']].to_numpy().ravel())\n",
    "\n",
    "# counts by label among similar rows\n",
    "n_label0 = (labels_arr[involved] == 0).sum()\n",
    "n_label1 = (labels_arr[involved] == 1).sum()\n",
    "\n",
    "print(f\"Similar rows total: {involved.size}\")\n",
    "print(f\"Label 0 (human)   : {n_label0}\")\n",
    "print(f\"Label 1 (AI)      : {n_label1}\")\n",
    "print(f\"Label 0 %         : {n_label0 / involved.size:.3%}\")\n",
    "print(f\"Label 1 %         : {n_label1 / involved.size:.3%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c36f3d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 487203\n",
      "After removing near-duplicates: 135968\n"
     ]
    }
   ],
   "source": [
    "# Get one representative row index per group\n",
    "keep_idx = nodes_df.groupby('group_id')['row_idx'].first().to_numpy()\n",
    "\n",
    "# Build a mask: keep all rows not in any group, plus one representative per group\n",
    "all_involved = set(nodes_df['row_idx'])\n",
    "rows_to_keep = set(keep_idx) | (set(range(len(df))) - all_involved)\n",
    "\n",
    "# Filter original df\n",
    "df_dedup = df.iloc[sorted(rows_to_keep)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Original rows: {len(df)}\")\n",
    "print(f\"After removing near-duplicates: {len(df_dedup)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a9e549e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135968, 4)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_dedup\n",
    "del df_dedup\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f6227df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df_drop_duplicates.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
