{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fffb7d8e",
   "metadata": {},
   "source": [
    "# Data Processing for Dataset 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ed6baf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45b7dda3",
   "metadata": {},
   "source": [
    "## 1. Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afbde28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique 'source' values (63):\n",
      "['Bloom-7B', 'Claude-Instant-v1', 'Claude-v1', 'Cohere-Command', 'Dolphin-2.5-Mixtral-8x7B', 'Dolphin-Mixtral-8x7B', 'Falcon-180B', 'Flan-T5-Base', 'Flan-T5-Large', 'Flan-T5-Small', 'Flan-T5-XL', 'Flan-T5-XXL', 'GLM-130B', 'GPT-3.5', 'GPT-4', 'GPT-J', 'GPT-NeoX', 'Gemini-Pro', 'Goliath-120B', 'Human', 'LLaMA-13B', 'LLaMA-2-70B', 'LLaMA-2-7B', 'LLaMA-30B', 'LLaMA-65B', 'LLaMA-7B', 'LZLV-70B', 'Mistral-7B', 'Mistral-7B-OpenOrca', 'Mixtral-8x7B', 'MythoMax-L2-13B', 'Neural-Chat-7B', 'Noromaid-20B', 'Nous-Capybara-34B', 'Nous-Capybara-7B', 'Nous-Hermes-LLaMA-2-13B', 'Nous-Hermes-LLaMA-2-70B', 'OPT-1.3B', 'OPT-125M', 'OPT-13B', 'OPT-2.7B', 'OPT-30B', 'OPT-350M', 'OPT-6.7B', 'OpenChat-3.5', 'OpenHermes-2-Mistral-7B', 'OpenHermes-2.5-Mistral-7B', 'PaLM-2', 'Psyfighter-13B', 'Psyfighter-2-13B', 'RWKV-5-World-3B', 'StripedHyena-Nous-7B', 'T0-11B', 'T0-3B', 'Text-Ada-001', 'Text-Babbage-001', 'Text-Curie-001', 'Text-Davinci-001', 'Text-Davinci-002', 'Text-Davinci-003', 'Toppy-M-7B', 'Unknown', 'YI-34B']\n",
      "\n",
      "Value counts (including NaN):\n",
      "source\n",
      "Human                       347692\n",
      "GPT-3.5                      52346\n",
      "Text-Davinci-003             22860\n",
      "Text-Davinci-002             21436\n",
      "OPT-1.3B                     18467\n",
      "                             ...  \n",
      "Toppy-M-7B                     433\n",
      "LLaMA-2-7B                     409\n",
      "Dolphin-Mixtral-8x7B           407\n",
      "Cohere-Command                 390\n",
      "Dolphin-2.5-Mixtral-8x7B       228\n",
      "Name: count, Length: 63, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "df3 = pd.read_csv(\"../data.csv\")\n",
    "\n",
    "# Sanity check\n",
    "if \"source\" not in df3.columns:\n",
    "    raise KeyError(\"Column 'source' not found in ./data.csv\")\n",
    "\n",
    "# Unique values\n",
    "unique_sources = df3[\"source\"].dropna().unique()\n",
    "print(f\"Unique 'source' values ({len(unique_sources)}):\")\n",
    "print(sorted(unique_sources))\n",
    "\n",
    "# (Optional) Counts per value\n",
    "print(\"\\nValue counts (including NaN):\")\n",
    "print(df3[\"source\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e14d5a",
   "metadata": {},
   "source": [
    "## 2. Rename Columns and Map Labels to 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67435fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated\n",
      "1    441230\n",
      "0    347692\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df3 = df3.rename(columns={\"source\": \"generated\"})\n",
    "\n",
    "# Map: Human -> 0, everything else -> 1\n",
    "df3[\"generated\"] = (\n",
    "    df3[\"generated\"].astype(str).str.strip().str.casefold().ne(\"human\")\n",
    ").astype(int)\n",
    "\n",
    "# (Optional) sanity check\n",
    "print(df3[\"generated\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f90fa257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Federal law supersedes state law, and cannabis...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>967</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miles feels restless after working all day. He...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5068</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So first of I am danish. That means that I fol...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1602</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this paper we present a novel rule-based ap...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5469</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Most social progressives, love democracy, and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2379</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated  prompt_id  \\\n",
       "0  Federal law supersedes state law, and cannabis...          1          0   \n",
       "1  Miles feels restless after working all day. He...          1          0   \n",
       "2  So first of I am danish. That means that I fol...          1          0   \n",
       "3  In this paper we present a novel rule-based ap...          1          0   \n",
       "4  Most social progressives, love democracy, and ...          1          0   \n",
       "\n",
       "   text_length  word_count  \n",
       "0          967         157  \n",
       "1         5068         778  \n",
       "2         1602         267  \n",
       "3         5469         848  \n",
       "4         2379         380  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d10d227",
   "metadata": {},
   "source": [
    "## 3. Filter Rows\n",
    "\n",
    "Keeping rows with word_count between 100-400 inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b87e2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_rows_in_range(df, col=\"word_count\", low=100, high=400):\n",
    "    \"\"\"Count rows where col value is between low and high inclusive.\"\"\"\n",
    "    return ((df[col] >= low) & (df[col] <= high)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4980b029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with word count between 100 and 400 inclusive: 270087\n"
     ]
    }
   ],
   "source": [
    "count = count_rows_in_range(df3, col=\"word_count\", low=100, high=400)\n",
    "print(f\"Rows with word count between 100 and 400 inclusive: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e89b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3[(df3[\"word_count\"] >= 100) & (df3[\"word_count\"] <= 400)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29eef971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270087, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce648f",
   "metadata": {},
   "source": [
    "## 4. Sampling 30,000 Rows Per Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93dc507b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated\n",
      "0    30000\n",
      "1    30000\n",
      "Name: count, dtype: int64\n",
      "Total rows: 60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dayso\\AppData\\Local\\Temp\\ipykernel_44564\\3958562842.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(n=target_n, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "target_n = 30_000\n",
    "\n",
    "counts = df3[\"generated\"].value_counts()\n",
    "too_small = counts[counts < target_n]\n",
    "if not too_small.empty:\n",
    "    raise ValueError(f\"These labels have fewer than {target_n} rows:\\n{too_small}\")\n",
    "\n",
    "# sample exactly 20k per label and shuffle\n",
    "df3 = (\n",
    "    df3.groupby(\"generated\", group_keys=False)\n",
    "       .apply(lambda g: g.sample(n=target_n, random_state=42))\n",
    "       .sample(frac=1.0, random_state=42)  # shuffle combined result\n",
    "       .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# quick confirmation\n",
    "print(df3[\"generated\"].value_counts())\n",
    "print(\"Total rows:\", len(df3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11142d75",
   "metadata": {},
   "source": [
    "## 5. Pre-Process Data & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "667d49d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "num_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c910a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import preprocess_text\n",
    "df3['tokens'] = Parallel(n_jobs=num_cores)(\n",
    "    delayed(preprocess_text)(text) for text in df3['text']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9421ac6f",
   "metadata": {},
   "source": [
    "### Deleting Overlaps \n",
    "\n",
    "Samples might appear in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1037fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./df1_cleaned_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "568e84ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of overlapping rows: 658\n"
     ]
    }
   ],
   "source": [
    "overlap = set(df['tokens']) & set(df3['tokens'])\n",
    "print(f\" Number of overlapping rows: {len(overlap)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d1d380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df3 = df3[~df3['tokens'].isin(df['tokens'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e8f2186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of overlapping rows: 0\n"
     ]
    }
   ],
   "source": [
    "overlap = set(df['tokens']) & set(df3['tokens'])\n",
    "print(f\" Number of overlapping rows: {len(overlap)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd38bfdf",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "455f7735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat, re, numpy as np\n",
    "import nltk\n",
    "from collections import Counter\n",
    "# Average sentence length\n",
    "def avg_sent_len(text):\n",
    "    sents = nltk.sent_tokenize(text)\n",
    "    return np.mean([len(nltk.word_tokenize(s)) for s in sents]) if sents else 0\n",
    "\n",
    "# Hapax ratio\n",
    "def hapax_ratio(tokens):\n",
    "    counts = Counter(tokens.split())\n",
    "    hapax = sum(1 for c in counts.values() if c == 1)\n",
    "    return hapax / len(tokens.split()) if tokens else 0\n",
    "\n",
    "# Flesch-Kincaid\n",
    "def flesch_grade(text):\n",
    "    try:\n",
    "        return textstat.flesch_kincaid_grade(text)\n",
    "    except:   # short texts may error\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47827c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['avg_sent_len'] = Parallel(n_jobs=num_cores)(\n",
    "    delayed(avg_sent_len)(text) for text in df3['text']\n",
    ")\n",
    "\n",
    "# Parallel for hapax_ratio\n",
    "df3['hapax_ratio'] = Parallel(n_jobs=num_cores)(\n",
    "    delayed(hapax_ratio)(tokens) for tokens in df3['tokens']\n",
    ")\n",
    "\n",
    "# Parallel for flesch_grade\n",
    "df3['flesch_grade'] = Parallel(n_jobs=num_cores)(\n",
    "    delayed(flesch_grade)(text) for text in df3['text']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cc633db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['ttr'] = df3['tokens'].apply(\n",
    "    lambda x: len(set(str(x).split())) / len(str(x).split()) if len(str(x).split()) > 0 else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5979fd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>tokens</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>hapax_ratio</th>\n",
       "      <th>flesch_grade</th>\n",
       "      <th>ttr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With parents both graduating from teacher coll...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>876</td>\n",
       "      <td>145</td>\n",
       "      <td>parent graduating teacher college teaching alw...</td>\n",
       "      <td>19.875000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>10.440129</td>\n",
       "      <td>0.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once, a man and a woman died at the same time ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1774</td>\n",
       "      <td>324</td>\n",
       "      <td>man woman died time sent hell together satan s...</td>\n",
       "      <td>15.440000</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>5.525511</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once upon a time, there was a woman named Emil...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>641</td>\n",
       "      <td>118</td>\n",
       "      <td>upon time woman named emily loved bake decided...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>7.084286</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They're called \"contrails,\" which is short for...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1220</td>\n",
       "      <td>197</td>\n",
       "      <td>called contrail short condensation trail creat...</td>\n",
       "      <td>21.636364</td>\n",
       "      <td>0.513761</td>\n",
       "      <td>9.680520</td>\n",
       "      <td>0.697248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I personally think that for once in a lifetime...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1901</td>\n",
       "      <td>357</td>\n",
       "      <td>personally think lifetime america say america ...</td>\n",
       "      <td>53.857143</td>\n",
       "      <td>0.487013</td>\n",
       "      <td>18.770053</td>\n",
       "      <td>0.655844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated  prompt_id  \\\n",
       "0  With parents both graduating from teacher coll...          0          0   \n",
       "1  Once, a man and a woman died at the same time ...          1          0   \n",
       "2  Once upon a time, there was a woman named Emil...          1          0   \n",
       "3  They're called \"contrails,\" which is short for...          0          0   \n",
       "4  I personally think that for once in a lifetime...          0          2   \n",
       "\n",
       "   text_length  word_count                                             tokens  \\\n",
       "0          876         145  parent graduating teacher college teaching alw...   \n",
       "1         1774         324  man woman died time sent hell together satan s...   \n",
       "2          641         118  upon time woman named emily loved bake decided...   \n",
       "3         1220         197  called contrail short condensation trail creat...   \n",
       "4         1901         357  personally think lifetime america say america ...   \n",
       "\n",
       "   avg_sent_len  hapax_ratio  flesch_grade       ttr  \n",
       "0     19.875000     0.800000     10.440129  0.887500  \n",
       "1     15.440000     0.539474      5.525511  0.684211  \n",
       "2     19.000000     0.649123      7.084286  0.789474  \n",
       "3     21.636364     0.513761      9.680520  0.697248  \n",
       "4     53.857143     0.487013     18.770053  0.655844  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcfd0e2",
   "metadata": {},
   "source": [
    "## 6. Save the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0a8a1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(\"processed_df3_60k_fe.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
