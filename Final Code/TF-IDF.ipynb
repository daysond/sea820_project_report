{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fffb7d8e",
   "metadata": {},
   "source": [
    "# Data Processing for Dataset 1 - AI Vs Human Text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b7dda3",
   "metadata": {},
   "source": [
    "## 1. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81df0f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>text_length</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_length</th>\n",
       "      <th>ttr</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>hapax_ratio</th>\n",
       "      <th>flesch_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>871</td>\n",
       "      <td>car wonderful thing perhaps one world greatest...</td>\n",
       "      <td>470</td>\n",
       "      <td>0.497872</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>0.317021</td>\n",
       "      <td>7.904784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cars are everywhere these days, and they are c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>633</td>\n",
       "      <td>car everywhere day commonplace among u getting...</td>\n",
       "      <td>380</td>\n",
       "      <td>0.544737</td>\n",
       "      <td>19.388889</td>\n",
       "      <td>0.357895</td>\n",
       "      <td>8.844641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One uses a car to go to thee store, pick someo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392</td>\n",
       "      <td>one us car go thee store pick someone even go ...</td>\n",
       "      <td>251</td>\n",
       "      <td>0.561753</td>\n",
       "      <td>16.814815</td>\n",
       "      <td>0.390438</td>\n",
       "      <td>7.509796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The electoral college ii iomething that hai be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>493</td>\n",
       "      <td>electoral college ii iomething hai loved hated...</td>\n",
       "      <td>262</td>\n",
       "      <td>0.538168</td>\n",
       "      <td>21.880000</td>\n",
       "      <td>0.366412</td>\n",
       "      <td>9.325487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear saaae senaaor, My leaaer is in regards ao...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>667</td>\n",
       "      <td>dear saaae senaaor leaaer regard ao changing a...</td>\n",
       "      <td>467</td>\n",
       "      <td>0.423983</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>0.265525</td>\n",
       "      <td>7.967523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated  text_length  \\\n",
       "0  Cars are a wonderful thing. They are perhaps o...        0.0          871   \n",
       "1  cars are everywhere these days, and they are c...        0.0          633   \n",
       "2  One uses a car to go to thee store, pick someo...        0.0          392   \n",
       "3  The electoral college ii iomething that hai be...        0.0          493   \n",
       "4  Dear saaae senaaor, My leaaer is in regards ao...        0.0          667   \n",
       "\n",
       "                                              tokens  token_length       ttr  \\\n",
       "0  car wonderful thing perhaps one world greatest...           470  0.497872   \n",
       "1  car everywhere day commonplace among u getting...           380  0.544737   \n",
       "2  one us car go thee store pick someone even go ...           251  0.561753   \n",
       "3  electoral college ii iomething hai loved hated...           262  0.538168   \n",
       "4  dear saaae senaaor leaaer regard ao changing a...           467  0.423983   \n",
       "\n",
       "   avg_sent_len  hapax_ratio  flesch_grade  \n",
       "0     19.300000     0.317021      7.904784  \n",
       "1     19.388889     0.357895      8.844641  \n",
       "2     16.814815     0.390438      7.509796  \n",
       "3     21.880000     0.366412      9.325487  \n",
       "4     18.500000     0.265525      7.967523  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from your local path\n",
    "df = pd.read_csv('./df1_cleaned_processed.csv')  \n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef8b0a2",
   "metadata": {},
   "source": [
    "## 2. TF-IDF - Logistic Regression w/ Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56bdc206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- columns we expect ----\n",
    "FEATURE_COLS = [\"tokens\", \"ttr\", \"hapax_ratio\", \"flesch_grade\"]\n",
    "TARGET_COL = \"generated\"\n",
    "\n",
    "# sanity check\n",
    "missing = [c for c in FEATURE_COLS + [TARGET_COL] if c not in df.columns]\n",
    "assert not missing, f\"Training df is missing columns: {missing}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c445f",
   "metadata": {},
   "source": [
    "### 2.1 Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aab24da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[FEATURE_COLS]\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75789e32",
   "metadata": {},
   "source": [
    "### 2.2 TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f8506cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transformer = TfidfVectorizer(\n",
    "    tokenizer=str.split,\n",
    "    ngram_range=(1, 2), # unigram and bigram\n",
    "    min_df=2,       \n",
    "    max_df=0.95,\n",
    "    max_features=10000,\n",
    "    sublinear_tf=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b272d",
   "metadata": {},
   "source": [
    "### 2.3 Feature Transformation\n",
    "\n",
    "- Vertorize the tokens\n",
    "\n",
    "- Normalize the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15e49792",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text\", text_transformer, \"tokens\"),                          \n",
    "        (\"num\", numeric_transformer, [\"ttr\",\"hapax_ratio\",\"flesch_grade\"])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34844bb",
   "metadata": {},
   "source": [
    "### 2.4 Define Pipeline & Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aecf24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dayso\\anaconda3\\envs\\pytorch_CV\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99     10508\n",
      "         1.0       1.00      0.99      0.99     10778\n",
      "\n",
      "    accuracy                           0.99     21286\n",
      "   macro avg       0.99      0.99      0.99     21286\n",
      "weighted avg       0.99      0.99      0.99     21286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ead258",
   "metadata": {},
   "source": [
    "### 2.5 Evaluation with Another Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5afbde28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV\n",
    "df2 = pd.read_csv(\"./processed_df3_60k_fe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b2d1019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.35      0.45     29660\n",
      "           1       0.55      0.81      0.66     29682\n",
      "\n",
      "    accuracy                           0.58     59342\n",
      "   macro avg       0.60      0.58      0.55     59342\n",
      "weighted avg       0.60      0.58      0.55     59342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure df2 has the required columns\n",
    "missing3 = [c for c in FEATURE_COLS if c not in df2.columns]\n",
    "assert not missing3, f\"df2 is missing columns: {missing3}\"\n",
    "\n",
    "X_df3 = df2[FEATURE_COLS]\n",
    "y_df3 = df2[TARGET_COL] if TARGET_COL in df2.columns else None\n",
    "\n",
    "y_df3_pred = clf.predict(X_df3)\n",
    "\n",
    "if y_df3 is not None:\n",
    "    print(classification_report(y_df3, y_df3_pred))\n",
    "else:\n",
    "    print(\"Predictions only (no ground-truth labels in df2):\")\n",
    "    print(y_df3_pred[:20])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c6c5e1",
   "metadata": {},
   "source": [
    "## 3. TF-IDF - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f3250",
   "metadata": {},
   "source": [
    "### 3.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8465ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dayso\\anaconda3\\envs\\pytorch_CV\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99     10508\n",
      "         1.0       1.00      0.99      0.99     10778\n",
      "\n",
      "    accuracy                           0.99     21286\n",
      "   macro avg       0.99      0.99      0.99     21286\n",
      "weighted avg       0.99      0.99      0.99     21286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define Vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=str.split,       # pre-tokenized text\n",
    "    ngram_range=(1, 2),        # unigrams + bigrams\n",
    "    min_df=2,                  # ignore words in fewer than 2 docs\n",
    "    max_df=0.95,               # ignore very frequent words\n",
    "    max_features=10000,        # limit feature space\n",
    "    sublinear_tf=True          # dampen high term frequencies\n",
    ")\n",
    "\n",
    "# Train-Test Split\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    df['tokens'], df['generated'], test_size=0.2, stratify=df['generated'], random_state=42\n",
    ")\n",
    "\n",
    "# Fit Transform & Training\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_text)\n",
    "X_test_tfidf = tfidf.transform(X_test_text)\n",
    "\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Report\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e284873",
   "metadata": {},
   "source": [
    "### 3.2 Examining Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "095f50c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AI-indicative terms:\n",
      "important: 6.790\n",
      "essay: 6.614\n",
      "additionally: 6.600\n",
      "super: 6.478\n",
      "potential: 5.991\n",
      "conclusion: 5.861\n",
      "hey: 5.798\n",
      "however: 4.726\n",
      "provide: 4.544\n",
      "essential: 4.186\n",
      "significant: 4.110\n",
      "unique: 3.844\n",
      "firstly: 3.826\n",
      "impact: 3.820\n",
      "sincerely name: 3.819\n",
      "cool: 3.816\n",
      "often: 3.767\n",
      "ensure: 3.645\n",
      "plus: 3.642\n",
      "totally: 3.583\n",
      "\n",
      "Top Human-indicative terms:\n",
      "would: -8.131\n",
      "going: -6.288\n",
      "go: -6.150\n",
      "student: -5.900\n",
      "although: -5.540\n",
      "people: -5.341\n",
      "school: -5.155\n",
      "paragraph: -5.079\n",
      "car: -4.968\n",
      "percent: -4.807\n",
      "get: -4.778\n",
      "person: -4.777\n",
      "human: -4.718\n",
      "said: -4.387\n",
      "many: -4.250\n",
      "driving: -4.203\n",
      "kid: -4.183\n",
      "reason: -4.134\n",
      "venus: -4.091\n",
      "probably: -4.051\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf.get_feature_names_out()\n",
    "coefs = clf.coef_[0]\n",
    "top_pos = sorted(zip(coefs, feature_names), reverse=True)[:20]\n",
    "top_neg = sorted(zip(coefs, feature_names))[:20]\n",
    "\n",
    "print(\"Top AI-indicative terms:\")\n",
    "for coef, word in top_pos:\n",
    "    print(f\"{word}: {coef:.3f}\")\n",
    "\n",
    "print(\"\\nTop Human-indicative terms:\")\n",
    "for coef, word in top_neg:\n",
    "    print(f\"{word}: {coef:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd0ef45",
   "metadata": {},
   "source": [
    "### 3.3 Evaluation with Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebb49035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.44      0.52     29660\n",
      "           1       0.57      0.74      0.64     29682\n",
      "\n",
      "    accuracy                           0.59     59342\n",
      "   macro avg       0.60      0.59      0.58     59342\n",
      "weighted avg       0.60      0.59      0.58     59342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_df3 = tfidf.transform(df2['tokens'])\n",
    "y_df3_true = df2['generated']\n",
    "y_df3_pred = clf.predict(X_df3)\n",
    "\n",
    "print(classification_report(y_df3_true, y_df3_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
